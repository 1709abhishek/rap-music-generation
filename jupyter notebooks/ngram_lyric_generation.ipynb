{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install eng_to_ipa\n",
        "import eng_to_ipa as ipa\n",
        "\n",
        "def is_vowel(character):\n",
        "\n",
        "    ipa_vowels = \"aeiou\"\n",
        "    return character in ipa_vowels\n",
        "\n",
        "def is_whitespace(character):\n",
        "    return character==' ' or character=='\\n'\n",
        "\n",
        "def get_phonetic_transcription(lyrics):\n",
        "    lines = lyrics.splitlines()\n",
        "    phonetic_lines = [ipa.convert(line) for line in lines]\n",
        "    phonetic = \"\\n\".join(phonetic_lines)\n",
        "\n",
        "    return phonetic\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "def syllable_similarity(bar1, bar2):\n",
        "    similarity = abs(syllables.estimate(bar1) - syllables.estimate(bar2))\n",
        "    return similarity\n",
        "\n",
        "def get_syllable_count_difference(lyrics):\n",
        "    lines = lyrics.splitlines()\n",
        "    i = 0\n",
        "    similarity = 0\n",
        "    while i < len(lines)-1:\n",
        "        similarity += syllable_similarity(lines[i], lines[i+1])\n",
        "        i += 2\n",
        "    return similarity/len(lines)\n",
        "\n",
        "def get_rhyme_density(lyrics, lookback=15):\n",
        "    bars = SongLyrics(lyrics, lookback)\n",
        "    return bars.avg_rhyme_length\n",
        "\n",
        "def get_longest_rhyme(lyrics, lookback=15):\n",
        "    bars = SongLyrics(lyrics, lookback)\n",
        "    return bars.get_longest_rhyme()[0]\n",
        "\n",
        "def get_unique_words(lyrics):\n",
        "    words = lyrics.split()\n",
        "    unique_words = set(words)\n",
        "    return len(unique_words)/len(words)\n",
        "\n",
        "def print_lyrics_stats(lyrics, lookback=15, artist=None, title=None):\n",
        "    bars = SongLyrics(lyrics, lookback, artist, title)\n",
        "    print(bars.title)\n",
        "    print('------------------------------------------')\n",
        "    print(\"Average rhyme length: %.3f\\n\" % bars.avg_rhyme_length)\n",
        "    bars.print_rhyme(bars.longest_rhyme)\n",
        "    print(\"Average syllable count difference: %.3f\\n\" % get_syllable_count_difference(lyrics))\n",
        "    print(\"Percentage unique words: %.3f\\n\" % get_unique_words(lyrics))\n",
        "\n",
        "\n",
        "\n",
        "class SongLyrics:\n",
        "    '''\n",
        "    This class is used to store and preprocess rap lyrics and calculate\n",
        "    statistics like average rhyme length out of the lyrics.\n",
        "    '''\n",
        "\n",
        "    def __init__(self, text=None, lookback=15, artist=None, title=None):\n",
        "        '''\n",
        "        Lyrics can be read from the file (default) or passed directly\n",
        "        to this constructor.\n",
        "        '''\n",
        "        self.raw_text = None\n",
        "        # How many previous words are checked for a rhyme.\n",
        "        self.lookback = lookback\n",
        "        self.raw_text = text\n",
        "        if artist == None or title == None:\n",
        "            self.title = \"Generated Song\"\n",
        "        else:\n",
        "            self.title = title + \" by \" + artist\n",
        "\n",
        "        if self.raw_text is not None:\n",
        "            cleaning_ok = self.clean_text(self.raw_text)\n",
        "            self.compute_vowel_representation()\n",
        "            self.avg_rhyme_length, self.longest_rhyme = self.calculate_rhyme_stats()\n",
        "\n",
        "    def clean_text(self, text):\n",
        "        '''\n",
        "        Preprocess text by removing unwanted characters and duplicate rows.\n",
        "        '''\n",
        "\n",
        "        self.text = text\n",
        "        # If there are more than 2 consecutive newlines, remove some of them\n",
        "        # (just to make the cleaned text look prettier)\n",
        "        self.text = re.sub('\\n\\n+', '\\n\\n', self.text)\n",
        "        # Remove duplicate rows\n",
        "        self.lines = self.text.split('\\n')\n",
        "\n",
        "        unique_lines = set()\n",
        "        new_text = ''\n",
        "        for line in self.lines:\n",
        "            line = line.strip()\n",
        "            if len(line) > 0 and line in unique_lines:\n",
        "                continue\n",
        "            # Remove lines that are within brackets/parenthesis\n",
        "            if len(line) >= 2 and ((line[0]=='[' and line[-1]==']') or (line[0]=='(' and line[-1]==')')):\n",
        "                continue\n",
        "            unique_lines.add(line)\n",
        "            new_text += line + '\\n'\n",
        "\n",
        "        self.text = new_text\n",
        "\n",
        "    def compute_vowel_representation(self):\n",
        "        '''\n",
        "        Compute a representation of the lyrics where only vowels are preserved.\n",
        "        '''\n",
        "        self.vowels_only = [] # Lyrics with all but vowels removed\n",
        "        self.vowel_indices = [] # Indices of the vowels in self.text list\n",
        "        self.word_end_indices = [] # Indices of the last characters of each word\n",
        "        self.words = [] # List of words in the lyrics\n",
        "        self.line_indices = []\n",
        "\n",
        "        self.original_text = self.text\n",
        "        self.text = get_phonetic_transcription(self.text)\n",
        "        self.original_word_end_indices = []\n",
        "        self.original_words = []\n",
        "\n",
        "        previous_space_index = -1 # Index of the previous space char\n",
        "        line_index = 0 # Line index of the current character\n",
        "        # Go through the lyrics char by char\n",
        "        for i in range(len(self.text)):\n",
        "            self.line_indices.append(line_index)\n",
        "            character = self.text[i]\n",
        "            if is_vowel(character):\n",
        "                # Ignore double vowels\n",
        "                if i > 0 and self.text[i-1] == character:\n",
        "                    # Index of a double vowel points to the latter occurrence\n",
        "                    self.vowel_indices[-1] = i\n",
        "                    continue\n",
        "                self.vowels_only.append(character)\n",
        "                self.vowel_indices.append(i)\n",
        "            elif is_whitespace(character):\n",
        "                if character in '\\n':\n",
        "                    line_index += 1\n",
        "                elif character in '.!?' and i < len(self.text)-1 and self.text[i+1] != '\\n':\n",
        "                    line_index += 1\n",
        "                if len(self.vowels_only) > 0 and not is_whitespace(self.text[i-1]):\n",
        "                    new_word = self.text[previous_space_index+1:self.vowel_indices[-1]+1]\n",
        "                    no_vowels = True\n",
        "                    for char in new_word:\n",
        "                        if is_vowel(char):\n",
        "                            no_vowels = False\n",
        "                            break\n",
        "                    if no_vowels:\n",
        "                        previous_space_index = i\n",
        "                        continue\n",
        "                    self.word_end_indices.append(len(self.vowels_only)-1)\n",
        "                    self.words.append(new_word)\n",
        "                previous_space_index = i\n",
        "\n",
        "        self.original_lines = self.original_text.split('\\n')\n",
        "\n",
        "    def rhyme_length(self, word_position_2):\n",
        "        '''\n",
        "        Length of rhyme (in vowels). The latter part of the rhyme ends with\n",
        "        word self.words[word_position_2].\n",
        "\n",
        "        Input:\n",
        "            word_position_2       Word index of the end of the rhyme.\n",
        "        '''\n",
        "        max_length = 0\n",
        "        max_word_position_1 = None\n",
        "        word_position_1 = max(0, word_position_2 - self.lookback)\n",
        "        while word_position_1 < word_position_2:\n",
        "            rhyme_length = self.fixed_rhyme_length(word_position_1, word_position_2)\n",
        "            if rhyme_length > max_length:\n",
        "                max_length = rhyme_length\n",
        "                max_word_position_1 = word_position_1\n",
        "            word_position_1 += 1\n",
        "        return max_length, max_word_position_1\n",
        "\n",
        "    def fixed_rhyme_length(self, word_position_1, word_position_2):\n",
        "        '''\n",
        "        Length of rhyme (in vowels). The first part of the rhyme ends with\n",
        "        self.words[word_position_1] and the latter part with word self.words[word_position_2].\n",
        "\n",
        "        Input:\n",
        "            word_position_1       Word index of the last word in the first part of the rhyme.\n",
        "            word_position_2       Word index of the end of the rhyme.\n",
        "        '''\n",
        "        if word_position_1 < 0:\n",
        "            return 0\n",
        "        elif self.words[word_position_1] == self.words[word_position_2]:\n",
        "            return 0\n",
        "        vowel_index_1 = self.word_end_indices[word_position_1]\n",
        "        vowel_index_2 = self.word_end_indices[word_position_2]\n",
        "        length = 0\n",
        "        while self.vowels_only[vowel_index_1 - length] == self.vowels_only[vowel_index_2 - length]:\n",
        "            if word_position_1 > 0 and vowel_index_1 - length <= self.word_end_indices[word_position_1 - 1] and word_position_2 > 0 and vowel_index_2 - length <= self.word_end_indices[word_position_2 - 1]:\n",
        "                prev_start_index_1 = self.vowel_indices[vowel_index_1 - length]\n",
        "                while prev_start_index_1 > 0 and not is_whitespace(self.text[prev_start_index_1 - 1]):\n",
        "                    prev_start_index_1 -= 1\n",
        "                prev_start_index_2 = self.vowel_indices[vowel_index_2 - length]\n",
        "                while prev_start_index_2 > 0 and not is_whitespace(self.text[prev_start_index_2 - 1]):\n",
        "                    prev_start_index_2 -= 1\n",
        "                next_start_index_1 = self.vowel_indices[vowel_index_1 - length]\n",
        "                while next_start_index_1 < len(self.text) - 1 and not is_whitespace(self.text[next_start_index_1 + 1]):\n",
        "                    next_start_index_1 += 1\n",
        "                next_start_index_2 = self.vowel_indices[vowel_index_2 - length]\n",
        "                while next_start_index_2 < len(self.text) - 1 and not is_whitespace(self.text[next_start_index_2 + 1]):\n",
        "                    next_start_index_2 += 1\n",
        "                if next_start_index_1 - prev_start_index_1 == next_start_index_2 - prev_start_index_2 and self.text[prev_start_index_1:next_start_index_1 + 1] == self.text[prev_start_index_2:next_start_index_2 + 1]:\n",
        "                    break\n",
        "            length += 1\n",
        "            if vowel_index_1 - length < 0 or vowel_index_2 - length <= vowel_index_1:\n",
        "                break\n",
        "        if length == 1:\n",
        "            length = 0\n",
        "        return length\n",
        "\n",
        "    def calculate_rhyme_stats(self):\n",
        "        '''\n",
        "        Compute the average rhyme length of the song and the longest rhyme.\n",
        "\n",
        "        Output:\n",
        "            Average rhyme length (float)\n",
        "            Longest rhyme which is a 3-tuple with:\n",
        "                (length, word index of the first part of the rhyme,\n",
        "                         word index of the latter part of the rhyme)\n",
        "        '''\n",
        "        rhyme_lengths = []\n",
        "        max_rhyme = (0, None, None)\n",
        "        for word_position_2 in range(1, len(self.word_end_indices)):\n",
        "            rhyme_length, word_position_1 = self.rhyme_length(word_position_2)\n",
        "            rhyme_lengths.append(rhyme_length)\n",
        "            if rhyme_length > max_rhyme[0]:\n",
        "                max_rhyme = (rhyme_length, word_position_1, word_position_2)\n",
        "        rhyme_lengths = np.array(rhyme_lengths)\n",
        "        if len(rhyme_lengths) > 0:\n",
        "            avg_rhyme_length = np.mean(rhyme_lengths)\n",
        "        else:\n",
        "            avg_rhyme_length = 0\n",
        "        return avg_rhyme_length, max_rhyme\n",
        "\n",
        "    def get_avg_rhyme_length(self):\n",
        "        return self.avg_rhyme_length\n",
        "\n",
        "    def print_song_stats(self):\n",
        "        print('------------------------------------------')\n",
        "        print(\"Avg rhyme length: %.3f\\n\" % self.avg_rhyme_length)\n",
        "\n",
        "        self.print_rhyme(self.longest_rhyme)\n",
        "\n",
        "    def print_rhyme(self, rhyme_tuple):\n",
        "        print(self.get_rhyme_str(rhyme_tuple))\n",
        "\n",
        "    def get_rhyme_str(self, rhyme_tuple):\n",
        "        ret = ''\n",
        "        rhyme_length, word_position_1, word_position_2 = rhyme_tuple\n",
        "        if word_position_1 is None or word_position_2 is None:\n",
        "            return ''\n",
        "        vowel_index_2 = self.vowel_indices[self.word_end_indices[word_position_2]]\n",
        "        vowel_index_2_original = vowel_index_2\n",
        "        while not is_whitespace(self.text[vowel_index_2]):\n",
        "            vowel_index_2 += 1\n",
        "        vowel_index_1 = self.vowel_indices[self.word_end_indices[word_position_1] - rhyme_length]\n",
        "        vowel_index_1_original = vowel_index_1\n",
        "        while self.text[vowel_index_1] != '\\n' and vowel_index_1 > 0:\n",
        "            vowel_index_1 -= 1\n",
        "\n",
        "        capitalized_line = ''\n",
        "        rhyming_vowels_1, rhyming_vowels_2 = self.get_rhyming_vowels(rhyme_tuple)\n",
        "        for i in range(vowel_index_1, vowel_index_2 + 1):\n",
        "            if i == min(rhyming_vowels_1) or i == min(rhyming_vowels_2):\n",
        "                capitalized_line += ' | ' + self.text[i]\n",
        "            elif i == max(rhyming_vowels_1) or i == max(rhyming_vowels_2):\n",
        "                capitalized_line += self.text[i] + '|'\n",
        "            else:\n",
        "                capitalized_line += self.text[i]\n",
        "        ret += \"Longest rhyme (l=%d): %s\\n\" % (rhyme_length, capitalized_line)\n",
        "        line_begin = self.line_indices[vowel_index_1]\n",
        "        line_end = self.line_indices[vowel_index_2]\n",
        "        for i in range(line_begin, line_end + 1):\n",
        "            if i < len(self.original_lines):\n",
        "                ret += self.original_lines[i] + '\\n'\n",
        "        return ret\n",
        "\n",
        "    def get_longest_rhyme(self):\n",
        "        rhyme_str = self.get_rhyme_str(self.longest_rhyme)\n",
        "        return self.longest_rhyme[0], rhyme_str\n",
        "\n",
        "    def get_rhyming_vowels(self, rhyme_tuple):\n",
        "        rhyme_length, word_position_1, word_position_2 = rhyme_tuple\n",
        "        if word_position_1 is None or word_position_2 is None:\n",
        "            return ([-1], [-1])\n",
        "\n",
        "        rhyming_vowels_1 = []\n",
        "        count_caps = 0\n",
        "        index = self.vowel_indices[self.word_end_indices[word_position_1]]\n",
        "        while count_caps < rhyme_length:\n",
        "            if is_vowel(self.text[index]):\n",
        "                rhyming_vowels_1.append(index)\n",
        "                if self.text[index] != self.text[index + 1]:\n",
        "                    count_caps += 1\n",
        "            index -= 1\n",
        "\n",
        "        rhyming_vowels_2 = []\n",
        "        count_caps = 0\n",
        "        index = self.vowel_indices[self.word_end_indices[word_position_2]]\n",
        "        last_index = index\n",
        "        while count_caps < rhyme_length:\n",
        "            if is_vowel(self.text[index]):\n",
        "                rhyming_vowels_2.append(index)\n",
        "                if index == last_index or self.text[index] != self.text[index + 1]:\n",
        "                    count_caps += 1\n",
        "            index -= 1\n",
        "\n",
        "        return (rhyming_vowels_1, rhyming_vowels_2)\n"
      ],
      "metadata": {
        "id": "xiuAJUUXNCvR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55381b77-229a-48ac-a524-e0b814813954"
      },
      "id": "xiuAJUUXNCvR",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: eng_to_ipa in /usr/local/lib/python3.10/dist-packages (0.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "ffa1950e",
      "metadata": {
        "id": "ffa1950e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import re\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.util import bigrams, ngrams, everygrams\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline, pad_both_ends\n",
        "from nltk.lm import MLE, KneserNeyInterpolated, Lidstone, Laplace, AbsoluteDiscountingInterpolated\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "e3e2490e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3e2490e",
        "outputId": "6ddcb847-bc21-415e-bbe8-64b58cb9c75f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "707c77b4",
      "metadata": {
        "id": "707c77b4"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "train_df\n",
        "train_df.rename({\"Lyrics\": \"lyric\", \"Title\": \"song\", \"Artist\": \"artist\"}, axis=1, inplace=True)\n",
        "test_df.rename({\"Lyrics\": \"lyric\", \"Title\": \"song\", \"Artist\": \"artist\"}, axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c65e083",
      "metadata": {
        "id": "9c65e083"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e08ea2df",
      "metadata": {
        "id": "e08ea2df"
      },
      "source": [
        "Default word tokenizer removes new line symbols."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "3646725a",
      "metadata": {
        "id": "3646725a"
      },
      "outputs": [],
      "source": [
        "# # Test\n",
        "# lyric = [word_tokenize(line) + ['\\n'] for line in train['lyric'][0].split('\\n')]\n",
        "# flat_list = list(itertools.chain(*lyric))[:-1]  # remove last new line symbol"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "9ce01738",
      "metadata": {
        "id": "9ce01738"
      },
      "outputs": [],
      "source": [
        "def tokenize(dataset):\n",
        "    return [\n",
        "        nltk.flatten(([\n",
        "            word_tokenize(line) + ['\\n']\n",
        "            for line in lyric.split('\\n')\n",
        "        ]))[:-1]\n",
        "        for lyric in list(dataset['lyric'])\n",
        "        if not isinstance(lyric, float)  # remove nan values\n",
        "    ]\n",
        "\n",
        "tokenized_train = tokenize(train_df)\n",
        "tokenized_test = tokenize(test_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f939fbc",
      "metadata": {
        "id": "9f939fbc"
      },
      "source": [
        "## Setup and stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "c758b751",
      "metadata": {
        "id": "c758b751"
      },
      "outputs": [],
      "source": [
        "N = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "c9314dc9",
      "metadata": {
        "id": "c9314dc9"
      },
      "outputs": [],
      "source": [
        "def generate_ngrams(dataset, every=False):\n",
        "    if every:\n",
        "        return [list(everygrams(pad_both_ends(example, n=N), max_len=N)) for example in dataset]\n",
        "    else:\n",
        "        return [list(ngrams(pad_both_ends(example, n=N), n=N)) for example in dataset]\n",
        "\n",
        "train_ngrams = generate_ngrams(tokenized_train, every=True)\n",
        "test_ngrams = generate_ngrams(tokenized_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "2f282f00",
      "metadata": {
        "id": "2f282f00"
      },
      "outputs": [],
      "source": [
        "def generate_vocabulary(dataset):\n",
        "    return list(nltk.lm.preprocessing.flatten(pad_both_ends(example, n=N) for example in dataset))\n",
        "\n",
        "train_vocabulary = generate_vocabulary(tokenized_train)\n",
        "test_vocabulary = generate_vocabulary(tokenized_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "dea2f950",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dea2f950",
        "outputId": "2c74e005-af59-4da0-9679-4e08d18a9ee7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set contains 6757 distinct tokens.\n",
            "Test set contains 3578 distinct tokens.\n",
            "Test set has 1148 tokens not in train test.\n"
          ]
        }
      ],
      "source": [
        "print(\"Training set contains\", len(set(train_vocabulary)), \"distinct tokens.\")\n",
        "print(\"Test set contains\", len(set(test_vocabulary)), \"distinct tokens.\")\n",
        "print(\"Test set has\", len(set(test_vocabulary) - set(train_vocabulary)), \"tokens not in train test.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "21a7f995",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21a7f995",
        "outputId": "253193fc-c468-4a75-c60a-aed41d3634b6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('\\n', 8628),\n",
              " (',', 5959),\n",
              " ('I', 3145),\n",
              " ('the', 2011),\n",
              " (\"'\", 1494),\n",
              " ('you', 1471),\n",
              " ('(', 1468),\n",
              " (')', 1468),\n",
              " ('a', 1204),\n",
              " ('it', 1164)]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "from collections import Counter\n",
        "Counter(train_vocabulary).most_common(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10a97e08",
      "metadata": {
        "id": "10a97e08"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "ddce41ef",
      "metadata": {
        "id": "ddce41ef"
      },
      "outputs": [],
      "source": [
        "lm = Lidstone(1e-4, N)\n",
        "lm.fit(train_ngrams, train_vocabulary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "675f3de9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "675f3de9",
        "outputId": "1c57138f-a092-4681-f315-02edf8f49e7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6758"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "len(lm.vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cda5d54f",
      "metadata": {
        "id": "cda5d54f"
      },
      "source": [
        "## evaluation metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34aa3e53",
      "metadata": {
        "id": "34aa3e53"
      },
      "source": [
        "### Perplexity (PPL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "7d344b69",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d344b69",
        "outputId": "94065a71-810d-4e44-8c08-b2a8d876b90d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34.729352351396486"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "lm.perplexity(nltk.lm.preprocessing.flatten(train_ngrams))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "792a8e64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "792a8e64",
        "outputId": "4e5351aa-7cf6-4c25-fcbe-99a97e5e4657"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "743.7346299905059"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "lm.perplexity(nltk.lm.preprocessing.flatten(test_ngrams))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da4544cf",
      "metadata": {
        "id": "da4544cf"
      },
      "source": [
        "### Generate songs after first line"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "04fd0475",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "04fd0475",
        "outputId": "168cf45f-c38e-4260-8a34-09d64bb30902"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n Oh yeah , yeah )\\nIf I do , I get it\\n\\n Girl I perform for ya\\n\\n I did ( ayy )\\n... </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s> </s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "re.sub(r'[ ]+\\n[ ]+', r'\\n', ' '.join(lm.generate(100, text_seed=['I', 'found'])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "df98d968",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df98d968",
        "outputId": "7517993d-37dd-442e-dced-c0d79928c586"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "110"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "first_lines = [song[:song.index('\\n')+1] for song in tokenized_test if '\\n' in song]\n",
        "len(first_lines)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "c4dde3e9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4dde3e9",
        "outputId": "268202bb-db1d-43a9-8add-726d7a2032c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['(', 'Ugh', ',', 'you', \"'re\", 'a', 'monster', ')', '\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "first_lines[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "7beaf3eb",
      "metadata": {
        "id": "7beaf3eb"
      },
      "outputs": [],
      "source": [
        "results = []\n",
        "for first_line in first_lines:\n",
        "    result = ' '.join(first_line)[:-2] + '\\n'\n",
        "    result += re.sub(r'[ ]+\\n[ ]+', r'\\n', ' '.join(lm.generate(100, text_seed=first_line, random_seed=0)))\n",
        "    result = re.sub(' </s>.*', '', result)\n",
        "    results.append(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "2fa7e08f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fa7e08f",
        "outputId": "53c71a2e-c316-4fe9-d3a6-2a1f02291d8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traphouse Mob\n",
            "Yoz , what , what I pay for hoes ( yeah )\n",
            "Shawty go jogging every morning )\n",
            "Bum bum be-dum bum ( I ca n't stress about no bitch 'cause I know\n",
            "Ooh , that I 'd like to fuck I look around , niggas spinnin '\n",
            "\n",
            " Guess we all Pisces\n",
            "Your last one standin ' in my hallways , I get down\n",
            "All the ladies , they love smoking and love drinking , some love deep inside of the storm when it feels like it when you turn the music up\n"
          ]
        }
      ],
      "source": [
        "print(results[8])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df8f3f1c",
      "metadata": {
        "id": "df8f3f1c"
      },
      "source": [
        "### Rhyme Density (RD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "fb9d4cbc",
      "metadata": {
        "id": "fb9d4cbc"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_rhyme_density(lyrics, lookback=15):\n",
        "    bars = SongLyrics(lyrics, lookback)\n",
        "    return bars.avg_rhyme_length\n",
        "results_rd = np.array([get_rhyme_density(song) for song in results])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "6f82a04c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f82a04c",
        "outputId": "dd618589-2bfa-4e96-dd8d-23cf6b3bbf97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.75"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "round(np.mean(results_rd),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "76c9012c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76c9012c",
        "outputId": "a97d8075-31a6-4644-a7b3-075d1537f980"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "round(np.std(results_rd),2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23e4a359",
      "metadata": {
        "id": "23e4a359"
      },
      "source": [
        "### Unique Words (UW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "6f36df49",
      "metadata": {
        "id": "6f36df49"
      },
      "outputs": [],
      "source": [
        "results_uw = np.array([get_unique_words(song) for song in results])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "0114cf14",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0114cf14",
        "outputId": "8965dce8-de56-45f9-eb95-c744f86dada4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.74 0.07\n"
          ]
        }
      ],
      "source": [
        "print(round(np.mean(results_uw),2), round(np.std(results_uw),2))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}